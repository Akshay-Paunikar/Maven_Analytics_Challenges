{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30864c7e",
   "metadata": {},
   "source": [
    "### Maven Everest Challenge\n",
    "\n",
    "Use data storytelling to visualize the evolution of mankind's pursuit of the world's highest peak.\n",
    "\n",
    "#### Challenge Objective:\n",
    "\n",
    "For the Maven Everest Challenge, you’ll play the role of a data journalist tasked with telling the story of mankind’s quest to conquer Mount Everest. Using real expedition data, your goal is to craft a compelling visual narrative that highlights things like key milestones, shifting strategies, and the climbers who dared to reach the top of the world.\n",
    "\n",
    "#### About The Data Set:\n",
    "\n",
    "This dataset, based on the archives of Elizabeth Hawley, provides a comprehensive record of mountaineering expeditions in the Nepalese Himalaya, spanning from 1905 to 2024. It includes detailed information on 89,000+ members across 11,000+ expeditions and 480 mountain peaks, including dates, successes, and significant events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4648773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# show full output\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ffa1deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the datasets\n",
    "expedition = pd.read_csv('E:\\Maven_Analytics_Challenges\\Everest_Challenge\\HimalayanExpeditions\\exped.csv')\n",
    "members = pd.read_csv('E:\\Maven_Analytics_Challenges\\Everest_Challenge\\HimalayanExpeditions\\members.csv')\n",
    "peaks = pd.read_csv('E:\\Maven_Analytics_Challenges\\Everest_Challenge\\HimalayanExpeditions\\peaks.csv')\n",
    "reference = pd.read_csv('E:\\\\Maven_Analytics_Challenges\\\\Everest_Challenge\\\\HimalayanExpeditions\\\\refer.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cdbe066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expedition shape: (11425, 65)\n",
      "Members shape: (89000, 61)\n",
      "Peaks shape: (480, 23)\n",
      "Reference shape: (15586, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Expedition shape:', expedition.shape)\n",
    "print('Members shape:', members.shape)\n",
    "print('Peaks shape:', peaks.shape)\n",
    "print('Reference shape:', reference.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3dc5c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's join the members and expedition dataframes on expid\n",
    "members_expedition = pd.merge(members, expedition, on='expid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d26cc018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89089, 125)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_expedition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "04b0bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check if values in peakid_x and peakid_y are same\n",
    "for i in range(len(members_expedition)):\n",
    "    if members_expedition['peakid_x'][i] != members_expedition['peakid_y'][i]:\n",
    "        print('Not same:', members_expedition['peakid_x'][i], members_expedition['peakid_y'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "80a42582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column peakid_y\n",
    "members_expedition.drop(columns=['peakid_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "046a4c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's join the members_expedition dataframe with the peaks dataframe on peakid\n",
    "members_expedition = pd.merge(members_expedition, peaks, left_on='peakid_x', right_on='peakid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "16a1a200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89089, 147)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_expedition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3ffdc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finally let's join the members_expedition dataframe with the reference dataframe on expid\n",
    "members_expedition = pd.merge(members_expedition, reference, on='expid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "510e5f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200037, 158)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_expedition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "bb7e5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's remove the columns that has more than 90% null values\n",
    "members_expedition = members_expedition.dropna(thresh=len(members_expedition) * 0.9, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c744bec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200037, 107)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_expedition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ea5f3246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110948"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicate records\n",
    "members_expedition.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "325c6c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89089, 107)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets remove the duplicate records\n",
    "members_expedition = members_expedition.drop_duplicates().reset_index(drop=True)\n",
    "members_expedition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2fe18028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fname', 'lname', 'citizen', 'msmtterm', 'route1', 'leaders', 'sponsor',\n",
       "       'smtdate', 'campsites', 'location', 'pyear', 'pseason', 'pmonth',\n",
       "       'pday', 'pexpid', 'pcountry', 'psummiters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colums with null values\n",
    "members_expedition.columns[members_expedition.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "7af0e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fill the null values in the columns with \"not available\"\n",
    "members_expedition = members_expedition.fillna('not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f5d2c2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_expedition.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "77e354cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colums with null values\n",
    "members_expedition.columns[members_expedition.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e35bdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check if values in peakid_x and peakid are same\n",
    "for i in range(len(members_expedition)):\n",
    "    if members_expedition['peakid_x'][i] != members_expedition['peakid'][i]:\n",
    "        print('Not same:', members_expedition['peakid_x'][i], members_expedition['peakid'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4e6b6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check if values in mseason and season are same\n",
    "for i in range(len(members_expedition)):\n",
    "    if members_expedition['mseason'][i] != members_expedition['season'][i]:\n",
    "        print('Not same:', members_expedition['mseason'][i], members_expedition['season'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "4aeb6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the peakid_x column\n",
    "members_expedition.drop(columns=['peakid_x', 'mseason'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "8db890f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expid         object\n",
       "membid         int64\n",
       "myear          int64\n",
       "fname         object\n",
       "lname         object\n",
       "sex           object\n",
       "citizen       object\n",
       "status        object\n",
       "leader          bool\n",
       "deputy          bool\n",
       "bconly          bool\n",
       "nottobc         bool\n",
       "support         bool\n",
       "disabled        bool\n",
       "hired           bool\n",
       "sherpa          bool\n",
       "tibetan         bool\n",
       "msuccess        bool\n",
       "mclaimed        bool\n",
       "mdisputed       bool\n",
       "msolo           bool\n",
       "mtraverse       bool\n",
       "mski            bool\n",
       "mparapente      bool\n",
       "mspeed          bool\n",
       "mhighpt         bool\n",
       "mroute1        int64\n",
       "mroute2        int64\n",
       "mroute3        int64\n",
       "mascent1       int64\n",
       "mascent2       int64\n",
       "mascent3       int64\n",
       "mo2used         bool\n",
       "mo2none         bool\n",
       "mo2climb        bool\n",
       "mo2descent      bool\n",
       "mo2sleep        bool\n",
       "mo2medical      bool\n",
       "death           bool\n",
       "deathhgtm      int64\n",
       "msmtbid       object\n",
       "msmtterm      object\n",
       "mchksum        int64\n",
       "year           int64\n",
       "season        object\n",
       "host          object\n",
       "route1        object\n",
       "nation        object\n",
       "leaders       object\n",
       "sponsor       object\n",
       "success1        bool\n",
       "success2        bool\n",
       "success3        bool\n",
       "success4        bool\n",
       "claimed         bool\n",
       "disputed        bool\n",
       "smtdate       object\n",
       "termreason    object\n",
       "highpoint      int64\n",
       "traverse        bool\n",
       "ski             bool\n",
       "parapente       bool\n",
       "camps          int64\n",
       "rope           int64\n",
       "totmembers     int64\n",
       "smtmembers     int64\n",
       "mdeaths        int64\n",
       "tothired       int64\n",
       "smthired       int64\n",
       "hdeaths        int64\n",
       "nohired         bool\n",
       "o2used          bool\n",
       "o2none          bool\n",
       "o2climb         bool\n",
       "o2descent       bool\n",
       "o2sleep         bool\n",
       "o2medical       bool\n",
       "o2taken         bool\n",
       "o2unkwn         bool\n",
       "campsites     object\n",
       "comrte          bool\n",
       "stdrte          bool\n",
       "primrte         bool\n",
       "primmem         bool\n",
       "primref         bool\n",
       "chksum         int64\n",
       "peakid        object\n",
       "pkname        object\n",
       "location      object\n",
       "heightm        int64\n",
       "heightf        int64\n",
       "himal         object\n",
       "region        object\n",
       "open            bool\n",
       "unlisted        bool\n",
       "trekking        bool\n",
       "phost         object\n",
       "pstatus       object\n",
       "pyear         object\n",
       "pseason       object\n",
       "pmonth        object\n",
       "pday          object\n",
       "pexpid        object\n",
       "pcountry      object\n",
       "psummiters    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members_expedition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6b62bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Standardize 'citizen' values by sorting country names and removing special characters\n",
    "def standardize_citizen(val):\n",
    "    # Remove special characters except for alphabets, numbers, spaces, and '/'\n",
    "    val = re.sub(r'[^A-Za-z0-9/ ]+', '', val)\n",
    "    # Split by '/', sort, and join back if multiple countries\n",
    "    if '/' in val:\n",
    "        countries = [c.strip() for c in val.split('/')]\n",
    "        countries = sorted(set(countries))\n",
    "        return '/'.join(countries)\n",
    "    return val.strip()\n",
    "\n",
    "members_expedition['citizen'] = members_expedition['citizen'].apply(standardize_citizen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ddaca295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still there are some inconsistencies in the 'citizen' column which need to be fixed like below\n",
    "members_expedition['citizen'] = members_expedition['citizen'].replace({'Nepal/India': 'India/Nepal', 'Nepal/India?': 'India/Nepal',\n",
    "                                                                       'India?': 'India', 'W Germany': 'Germany',\n",
    "                                                                       'Malaysi': 'Malaysia',\n",
    "                                                                       'Iran/W Germany': 'Germany/Iran',\n",
    "                                                                       'Lativa/USA': 'Latvia/USA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "766ce526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have cleaned the data, let's save the cleaned data to a csv file\n",
    "members_expedition.to_csv('E:\\Maven_Analytics_Challenges\\Everest_Challenge\\HimalayanExpeditions\\members_expedition.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
